{{- if and .Values.observability.enabled .Values.observability.opentelemetry.enabled }}
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: {{ include "soperator-fluxcd.fullname" . }}-opentelemetry-collector-logs
  labels:
  {{- include "soperator-fluxcd.labels" . | nindent 4 }}
spec:
  chart:
    spec:
      chart: opentelemetry-collector
      interval: {{ .Values.observability.opentelemetry.logs.interval }}
      sourceRef:
        kind: HelmRepository
        name: {{ include "soperator-fluxcd.fullname" . }}-opentelemetry-collector
      version: {{ .Values.observability.opentelemetry.logs.version }}
  dependsOn:
  - name: {{ include "soperator-fluxcd.fullname" . }}-ns
  - name: {{ include "soperator-fluxcd.fullname" . }}-vm-logs
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
      remediateLastFailure: true
  interval: {{ .Values.observability.opentelemetry.logs.interval }}
  timeout: {{ .Values.observability.opentelemetry.logs.timeout }}
  releaseName: opentelemetry-collector-logs
  targetNamespace: logs-system
  values:
  {{- $hasPublicEndpoint := .Values.observability.publicEndpointEnabled }}
  {{- if .Values.observability.opentelemetry.logs.overrideValues }}
    {{- toYaml .Values.observability.opentelemetry.logs.overrideValues | nindent 4 }}
  {{- else }}
    clusterRole:
      create: true
      rules:
      - apiGroups:
        - ""
        resources:
        - pods
        - namespaces
        verbs:
        - get
        - watch
        - list
    config:
      exporters:
        otlphttp/victoriametrics:
          compression: gzip
          encoding: proto
          logs_endpoint: http://vm-logs-victoria-logs-single-server:9428/insert/opentelemetry/v1/logs
          retry_on_failure:
            initial_interval: 200ms
          timeout: 5s
        {{- if $hasPublicEndpoint }}
        otlp:
          endpoint: dns:///write.logging.eu-north1.nebius.cloud.:443
          balancer_name: round_robin
          compression: snappy
          retry_on_failure:
            initial_interval: 200ms
          timeout: 5s
          headers:
            iam-container: project-e00h61cxzwnf6zksvdn77
          auth:
            authenticator: bearertokenauth
        {{- end }}
      extensions:
        {{- if .Values.observability.opentelemetry.logs.values.hcOutputEnabled }}
        k8s_observer:
          node: ${env:K8S_NODE_NAME}
        {{- end }}
        file_storage:
          directory: /var/lib/otelcol
        health_check:
          endpoint: 0.0.0.0:13133
        {{- if $hasPublicEndpoint }}
        bearertokenauth:
          filename: "/o11ytoken/accessToken"
        {{- end }}
      processors:
        batch:
          send_batch_max_size: 700
          send_batch_size: 250
        k8sattributes:
          extract:
            labels:
            - from: pod
              key: external-o11y
              tag_name: external_o11y
            - from: namespace
              key: o11y_resource_id
              tag_name: resource_id
            - from: namespace
              key: o11y_service_provider
              tag_name: service_provider
            metadata:
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.pod.start_time
          filter:
            node_from_env_var: K8S_NODE_NAME
          passthrough: false
          pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.uid
          - sources:
            - from: connection
          wait_for_metadata: true
          wait_for_metadata_timeout: 30s
        memory_limiter:
          check_interval: 5s
          limit_percentage: 80
          spike_limit_percentage: 25
        transform:
          log_statements:
          - context: log
            error_mode: ignore
            statements:
            - set(attributes["cluster"], "${env:CLUSTER_NAME}")
            - set(attributes["k8s.node.name"], "${env:K8S_NODE_NAME}")
      receivers:
        {{- if .Values.observability.opentelemetry.logs.values.hcOutputEnabled }}
        receiver_creator:
          watch_observers: [k8s_observer]
          receivers:
            filelog:
              rule: type == "pod" && name matches "worker-"
              config:
                include: 
                  - "/mnt/jail/opt/hc_out/`name`/**/*.out"
        {{- end }}
        filelog/nodelogs:
          include:
            - '/var/nodelogs/kern.log*'
            - '/var/nodelogs/syslog*'
            - '/var/nodelogs/dmesg*'
            - '/var/nodelogs/fabricmanager.log*'
          exclude:
            - '/var/nodelogs/*.gz'
            - '/var/nodelogs/*.tmp'
          include_file_name: true
          operators:
            - type: add
              field: resource["o11y_agent_raw_logs"]
              value: 'yes'
            - type: add
              field: resource["workspace.id"]
              value: node-system
            - id: extract_logtype
              type: regex_parser
              parse_from: attributes["log.file.name"]
              regex: '^(?P<logtype>[^.]+).*$'
            - type: remove
              field: attributes["log.file.name"]
            - id: get-format
              type: router
              routes:
                - expr: attributes["logtype"] matches "syslog|kern"
                  output: parse-syslog
              default: not-syslog
            - id: parse-syslog
              type: syslog_parser
              protocol: rfc3164
              allow_skip_pri_header: true
            - type: move
              from: attributes["message"]
              to: body
              if: '"message" in attributes'
            - id: not-syslog
              type: noop
            - type: move
              from: attributes["logtype"]
              to: resource["app.kubernetes.io/name"]
        filelog/pods:
          exclude:
          - /var/log/pods/*/otc-container/*.log
          - /var/log/pods/*/munge/*.log
          - /var/log/pods/kube-system_hubble-*/**/*.log
          - /var/log/pods/monitoring-system_*/**/*.log
          - /var/log/pods/logs-system_*/**/*.log
          include:
          - /var/log/pods/*-system_*/**/*.log
          - /var/log/pods/soperator_*/**/*.log
          include_file_name: false
          include_file_path: true
          operators:
          - id: get-format
            routes:
            - expr: body matches "^[^ Z]+Z"
              output: parser-containerd
            - expr: body matches "^\\{"
              output: parser-docker
            type: router
          - id: parser-docker
            output: extract_metadata_from_filepath
            timestamp:
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
              parse_from: attributes.timestamp
            type: json_parser
          - combine_field: attributes.log
            combine_with: ""
            id: crio-recombine
            is_last_entry: attributes.logtag == 'F'
            max_log_size: 102400
            output: extract_metadata_from_filepath
            source_identifier: attributes["log.file.path"]
            type: recombine
          - id: parser-containerd
            regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
              ?(?P<log>.*)$
            timestamp:
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
              parse_from: attributes.time
            type: regex_parser
          - combine_field: attributes.log
            combine_with: ""
            id: containerd-recombine
            is_last_entry: attributes.logtag == 'F'
            max_log_size: 102400
            output: extract_metadata_from_filepath
            source_identifier: attributes["log.file.path"]
            type: recombine
          - id: extract_metadata_from_filepath
            parse_from: attributes["log.file.path"]
            regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
            type: regex_parser
          - from: attributes.stream
            to: attributes["log.iostream"]
            type: move
          - from: attributes.container_name
            to: resource["k8s.container.name"]
            type: move
          - from: attributes.namespace
            to: resource["k8s.namespace.name"]
            type: move
          - from: attributes.pod_name
            to: resource["k8s.pod.name"]
            type: move
          - from: attributes.restart_count
            to: resource["k8s.container.restart_count"]
            type: move
          - from: attributes.uid
            to: resource["k8s.pod.uid"]
            type: move
          - from: attributes.log
            to: body
            type: move
          - field: attributes.level
            type: add
            value: unknown
          - id: parse-json-logs
            if: body matches "^\\{.+\\}$"
            parse_from: body
            parse_to: attributes
            severity:
              mapping:
                debug:
                - debug
                - DEBUG
                error:
                - error
                - ERROR
                fatal:
                - fatal
                - FATAL
                info:
                - info
                - INFO
                warn:
                - warn
                - WARN
                - warning
                - WARNING
              parse_from: attributes.level
            type: json_parser
          retry_on_failure:
            enabled: true
          start_at: end
          storage: file_storage
        zipkin: null
      service:
        extensions:
        - health_check
        - file_storage
        {{- if $hasPublicEndpoint }}
        - bearertokenauth
        {{- end }}
        {{- if .Values.observability.opentelemetry.logs.values.hcOutputEnabled }}
        - k8s_observer
        {{- end }}
        pipelines:
          logs:
            exporters:
            - otlphttp/victoriametrics
            {{- if $hasPublicEndpoint }}
            - otlp
            {{- end }}
            processors:
            - k8sattributes
            - transform
            - memory_limiter
            - batch
            receivers:
            - filelog/pods
            - filelog/nodelogs
            {{- if .Values.observability.opentelemetry.logs.values.hcOutputEnabled }}
            - receiver_creator
            {{- end }}
          metrics: null
          traces: null
    extraEnvs:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: CLUSTER_NAME
      value: {{ .Values.observability.clusterName | quote }}
    - name: GOMAXPROCS
      value: "1"
    extraVolumeMounts:
    {{- if $hasPublicEndpoint }}
    - mountPath: /o11ytoken
      name: o11ytoken
      readOnly: true
    {{- end }}
    - mountPath: /var/log/pods
      name: varlogpods
      readOnly: true
    - mountPath: /var/lib/docker/containers
      name: varlibdockercontainers
      readOnly: true
    - mountPath: /var/lib/otelcol
      name: varlibotelcol
    - name: node-logs
      mountPath: /var/nodelogs
      readOnly: true
    {{- if .Values.observability.opentelemetry.logs.values.hcOutputEnabled }}
    - mountPath: /mnt/jail/opt/hc_out
      name: hc-logs
      readOnly: true
    {{- end }}
    extraVolumes:
    {{- if $hasPublicEndpoint }}
    - name: o11ytoken
      secret:
        secretName: o11y-writer-sa-token
    {{- end }}
    - hostPath:
        path: /var/log/pods
      name: varlogpods
    - hostPath:
        path: /var/log
        type: Directory
      name: node-logs
    {{- if .Values.observability.opentelemetry.logs.values.hcOutputEnabled }}
    - hostPath:
        path: /mnt/jail/opt/hc_out
        type: Directory
      name: hc-logs
    {{- end }}
    - hostPath:
        path: /var/lib/otelcol
        type: DirectoryOrCreate
      name: varlibotelcol
    - hostPath:
        path: /var/lib/docker/containers
      name: varlibdockercontainers
    image:
      pullPolicy: IfNotPresent
      repository: cr.eu-north1.nebius.cloud/observability/nebius-o11y-agent
      tag: 0.2.267
    initContainers:
    - command:
      - sh
      - -c
      - 'chown -R 10001: /var/lib/otelcol /var/nodelogs'
      image: cr.eu-north1.nebius.cloud/soperator/busybox:latest
      name: init-fs
      securityContext:
        runAsGroup: 0
        runAsUser: 0
      volumeMounts:
      - mountPath: /var/lib/otelcol
        name: varlibotelcol
      - name: node-logs
        mountPath: /var/nodelogs
    mode: daemonset
    rollout:
      rollingUpdate:
        maxUnavailable: 50%
      strategy: RollingUpdate
    securityContext:
      runAsGroup: 0
      runAsUser: 10001
    serviceAccount:
      create: true
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    - effect: NoSchedule
      key: node.cilium.io/agent-not-ready
      operator: Exists
    useGOMEMLIMIT: {{ .Values.observability.opentelemetry.logs.values.useGOMEMLIMIT | default true }}
    {{- if and .Values.observability.opentelemetry.logs.values .Values.observability.opentelemetry.logs.values.resources }}
    resources: {{- toYaml .Values.observability.opentelemetry.logs.values.resources | nindent 6 }}
    {{- end }}
  {{- end }}
  valuesFrom:
  - kind: ConfigMap
    name: terraform-opentelemetry-collector-logs
    optional: true
    valuesKey: values.yaml
  - kind: ConfigMap
    name: opentelemetry-collector-logs
    optional: true
    valuesKey: values.yaml
{{- end }}
