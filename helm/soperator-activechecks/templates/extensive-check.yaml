apiVersion: slurm.nebius.ai/v1alpha1
kind: ActiveCheck
metadata:
  name: "extensive-check"
spec:
  name: "extensive-check"
  checkType: "slurmJob"
  dependsOn: [ "wait-for-soperatorchecks-srun-ready", "wait-for-topology", "prepull-container-image" ]
  slurmClusterRefName: {{ .Values.slurmClusterRefName | quote }}
  # extensive-check is suspended and its schedule is not used.
  # It is being scheduled using `cronjob/run-extensive-check-on-reservations`
  suspend: {{ .Values.checks.extensiveCheck.suspend }}
  runAfterCreation: {{ .Values.checks.extensiveCheck.runAfterCreation }}
  schedule: "0 0 1 1 *"
  # *JobsHistoryLimit this sould equal the number of worker nodes in the cluster
  successfulJobsHistoryLimit: 3000
  failedJobsHistoryLimit: 3000
  slurmJobSpec:
    sbatchScript: |
{{ tpl (.Files.Get "scripts/extensive-check.sh") . | indent 6 }}
    jobContainer:
      image: {{ .Values.images.slurmJob | quote }}
      env:
{{ toYaml .Values.jobContainer.env | indent 8 }}
        - name: "SLURM_EXTRA_COMMENT_JSON"
          value: {{ .Values.checks.extensiveCheck.extraCommentJson | quote }}
      volumeMounts:
{{ toYaml .Values.jobContainer.volumeMounts | indent 8 }}
      volumes:
{{ toYaml .Values.jobContainer.volumes | indent 8 }}
    mungeContainer:
      image: {{ .Values.images.munge | quote }}
  successReactions:
    removeReservation:
      prefix: {{ .Values.checks.extensiveCheck.reservationPrefix | quote }}
  failureReactions:
    drainSlurmNode:
      drainReasonPrefix: {{ .Values.checks.extensiveCheck.drainReasonPrefix | quote }}
    removeReservation:
      prefix: {{ .Values.checks.extensiveCheck.reservationPrefix | quote }}
